{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e652068f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ambient_humidity</th>\n",
       "      <th>baking_duration</th>\n",
       "      <th>cooling_period</th>\n",
       "      <th>cream_fat_content</th>\n",
       "      <th>egg_temperature</th>\n",
       "      <th>egg_yolk_count</th>\n",
       "      <th>final_temperature</th>\n",
       "      <th>lemon_zest_ph</th>\n",
       "      <th>notes_baker</th>\n",
       "      <th>origin</th>\n",
       "      <th>oven_temperature</th>\n",
       "      <th>pastry_type</th>\n",
       "      <th>preheating_time</th>\n",
       "      <th>salt_ratio</th>\n",
       "      <th>sugar_content</th>\n",
       "      <th>vanilla_extract</th>\n",
       "      <th>quality_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>100.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pastel Nata</td>\n",
       "      <td>207.0</td>\n",
       "      <td>42.74</td>\n",
       "      <td>22.8</td>\n",
       "      <td>5.7</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>306.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>245.0</td>\n",
       "      <td>41.73</td>\n",
       "      <td>11.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>99.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Porto</td>\n",
       "      <td>121.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186.0</td>\n",
       "      <td>75.10</td>\n",
       "      <td>20.3</td>\n",
       "      <td>7.5</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>357.0</td>\n",
       "      <td>Pastel de Nata</td>\n",
       "      <td>186.0</td>\n",
       "      <td>46.41</td>\n",
       "      <td>73.3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>100.1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>202.0</td>\n",
       "      <td>Pastel de nata</td>\n",
       "      <td>218.0</td>\n",
       "      <td>56.52</td>\n",
       "      <td>80.1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>60.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>222.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>177.0</td>\n",
       "      <td>34.42</td>\n",
       "      <td>58.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5197</th>\n",
       "      <td>61.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>96.4</td>\n",
       "      <td>99.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>366.0</td>\n",
       "      <td>Pastel De Nata</td>\n",
       "      <td>224.0</td>\n",
       "      <td>46.18</td>\n",
       "      <td>141.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5198</th>\n",
       "      <td>69.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>97.7</td>\n",
       "      <td>90.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>203.0</td>\n",
       "      <td>Pastel de nata</td>\n",
       "      <td>158.0</td>\n",
       "      <td>28.46</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5199</th>\n",
       "      <td>70.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>101.2</td>\n",
       "      <td>139.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>391.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>196.0</td>\n",
       "      <td>56.92</td>\n",
       "      <td>188.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5200</th>\n",
       "      <td>54.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>95.8</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>346.0</td>\n",
       "      <td>Pastel de nata</td>\n",
       "      <td>174.0</td>\n",
       "      <td>53.50</td>\n",
       "      <td>17.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5200 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ambient_humidity  baking_duration  cooling_period  cream_fat_content  \\\n",
       "id                                                                           \n",
       "1                 54.0             24.0            26.0              100.4   \n",
       "2                 66.0             37.0            34.0               98.0   \n",
       "3                 41.0             30.0            19.0               99.3   \n",
       "4                 62.0             24.0            48.0               98.0   \n",
       "5                 55.0             21.0            34.0              100.1   \n",
       "...                ...              ...             ...                ...   \n",
       "5196              60.0             18.0            35.0               96.0   \n",
       "5197              61.0             25.0            40.0               96.4   \n",
       "5198              69.0             18.0            36.0               97.7   \n",
       "5199              70.0             25.0            40.0              101.2   \n",
       "5200              54.0             26.0            39.0               95.8   \n",
       "\n",
       "      egg_temperature  egg_yolk_count  final_temperature  lemon_zest_ph  \\\n",
       "id                                                                        \n",
       "1                52.0            11.0              309.0            3.2   \n",
       "2                46.0            10.0              317.0            3.3   \n",
       "3                53.0            10.0              130.0            3.4   \n",
       "4               115.0             9.0              354.0            3.3   \n",
       "5                48.0             9.0              211.0            3.0   \n",
       "...               ...             ...                ...            ...   \n",
       "5196             72.0            11.0              215.0            3.3   \n",
       "5197             99.0             9.0              367.0            3.2   \n",
       "5198             90.0            11.0              206.0            3.6   \n",
       "5199            139.0             9.0              414.0            3.1   \n",
       "5200             36.0            10.0              333.0            3.5   \n",
       "\n",
       "      notes_baker   origin  oven_temperature     pastry_type  preheating_time  \\\n",
       "id                                                                              \n",
       "1             NaN   Lisboa               NaN     Pastel Nata            207.0   \n",
       "2             NaN   Lisboa             306.0             NaN            245.0   \n",
       "3             NaN    Porto             121.0             NaN            186.0   \n",
       "4             NaN   Lisboa             357.0  Pastel de Nata            186.0   \n",
       "5             NaN   Lisboa             202.0  Pastel de nata            218.0   \n",
       "...           ...      ...               ...             ...              ...   \n",
       "5196          NaN  Lisboa              222.0             NaN            177.0   \n",
       "5197          NaN   Lisboa             366.0  Pastel De Nata            224.0   \n",
       "5198          NaN   Lisboa             203.0  Pastel de nata            158.0   \n",
       "5199          NaN   Lisboa             391.0             NaN            196.0   \n",
       "5200          NaN  Lisboa              346.0  Pastel de nata            174.0   \n",
       "\n",
       "      salt_ratio  sugar_content  vanilla_extract quality_class  \n",
       "id                                                              \n",
       "1          42.74           22.8              5.7            KO  \n",
       "2          41.73           11.6              4.0            KO  \n",
       "3          75.10           20.3              7.5            OK  \n",
       "4          46.41           73.3              4.2            OK  \n",
       "5          56.52           80.1              6.0            KO  \n",
       "...          ...            ...              ...           ...  \n",
       "5196       34.42           58.9              5.7            OK  \n",
       "5197       46.18          141.4              6.5            KO  \n",
       "5198       28.46           10.0              6.0            OK  \n",
       "5199       56.92          188.9              5.7            KO  \n",
       "5200       53.50           17.9              4.5            KO  \n",
       "\n",
       "[5200 rows x 17 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_learn = pd.read_csv('Nata_Files/learn_modified.csv', index_col=0)\n",
    "dataset_learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97502d63",
   "metadata": {},
   "source": [
    "## **Notebook 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dc401f",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd81d1a7",
   "metadata": {},
   "source": [
    "load data\n",
    "remove columns\n",
    "\n",
    "missing values\n",
    "outliers\n",
    "check duplicates\n",
    "check and correct data types\n",
    "Visualize distributions (boxplots, z-scores, or IQR method).\n",
    "\n",
    "Explain whether you remove, cap, or keep outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93778b5",
   "metadata": {},
   "source": [
    "### **2.1. Categorical Data Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f38a86",
   "metadata": {},
   "source": [
    "As we saw in the first notebook, the column `origin`, which keeps track of where the bakery is located (Lisbon or Porto), has a lot of inconsistencies in the names of those cities. 'Lisboa' and 'Porto' are written in a lot of different ways, therefore, we decided to start Notebook 2 deleting those differences, replacing all the values with either 'Lisboa' and 'Porto' written exactly in like that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a436d0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['lisboa', 'porto', ' lisboa', 'porto ', nan, 'lisboa ', ' porto'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in these lines of code we changed all the values of the column 'origin' to lowercase letters\n",
    "#then, we checked the unique values of that column to see the differences that were still in the dataset\n",
    "dataset_learn['origin'] = dataset_learn['origin'].str.lower()\n",
    "dataset_learn['origin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de8549f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Lisboa', 'Porto', nan], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_learn['origin'] = dataset_learn['origin'].replace({'lisboa': 'Lisboa',' lisboa': 'Lisboa', 'lisboa ': 'Lisboa', 'porto': 'Porto', ' porto': 'Porto', 'porto ': 'Porto'})\n",
    "dataset_learn['origin'].unique()\n",
    "#here, we deleted all the differences and now we are left with only 'Lisboa', 'Porto' and obviously missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa7414d",
   "metadata": {},
   "source": [
    "### **2.2. Removal of Columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1f01b1",
   "metadata": {},
   "source": [
    "The column `notes_baker` has 5200 missing values, which means it does not give us any useful information, therefore, we decided to remove it. \\\n",
    " Additionally, the column `pastry_type` is a constant. It does not add any predictive value to our project, so, after checking if there are any values other than 'Pastel de Nata' written in different ways, we will also remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28572f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_learn.drop(['notes_baker'], axis = 1, inplace = True) #drops the notes_baker column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba3191ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pastel Nata' nan 'Pastel de Nata' 'Pastel de nata' 'Pastel De Nata']\n"
     ]
    }
   ],
   "source": [
    "print(dataset_learn['pastry_type'].unique()) #checks if there are different pastry types in the dataset, as there are none, we can delete this column too\n",
    "dataset_learn.drop(['pastry_type'], axis = 1, inplace = True) #drops the pastry_type column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6423ce99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ambient_humidity</th>\n",
       "      <th>baking_duration</th>\n",
       "      <th>cooling_period</th>\n",
       "      <th>cream_fat_content</th>\n",
       "      <th>egg_temperature</th>\n",
       "      <th>egg_yolk_count</th>\n",
       "      <th>final_temperature</th>\n",
       "      <th>lemon_zest_ph</th>\n",
       "      <th>origin</th>\n",
       "      <th>oven_temperature</th>\n",
       "      <th>preheating_time</th>\n",
       "      <th>salt_ratio</th>\n",
       "      <th>sugar_content</th>\n",
       "      <th>vanilla_extract</th>\n",
       "      <th>quality_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>100.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>207.0</td>\n",
       "      <td>42.74</td>\n",
       "      <td>22.8</td>\n",
       "      <td>5.7</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ambient_humidity  baking_duration  cooling_period  cream_fat_content  \\\n",
       "id                                                                         \n",
       "1               54.0             24.0            26.0              100.4   \n",
       "\n",
       "    egg_temperature  egg_yolk_count  final_temperature  lemon_zest_ph  origin  \\\n",
       "id                                                                              \n",
       "1              52.0            11.0              309.0            3.2  Lisboa   \n",
       "\n",
       "    oven_temperature  preheating_time  salt_ratio  sugar_content  \\\n",
       "id                                                                 \n",
       "1                NaN            207.0       42.74           22.8   \n",
       "\n",
       "    vanilla_extract quality_class  \n",
       "id                                 \n",
       "1               5.7            KO  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_learn.head(1) #just to make sure the columns were deleted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950cefe4",
   "metadata": {},
   "source": [
    "### **2.3. Handling Duplicate Records**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8443d174",
   "metadata": {},
   "source": [
    "In this section, we'll check if there any duplicate records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "123b53a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ambient_humidity</th>\n",
       "      <th>baking_duration</th>\n",
       "      <th>cooling_period</th>\n",
       "      <th>cream_fat_content</th>\n",
       "      <th>egg_temperature</th>\n",
       "      <th>egg_yolk_count</th>\n",
       "      <th>final_temperature</th>\n",
       "      <th>lemon_zest_ph</th>\n",
       "      <th>origin</th>\n",
       "      <th>oven_temperature</th>\n",
       "      <th>preheating_time</th>\n",
       "      <th>salt_ratio</th>\n",
       "      <th>sugar_content</th>\n",
       "      <th>vanilla_extract</th>\n",
       "      <th>quality_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>100.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>207.0</td>\n",
       "      <td>42.74</td>\n",
       "      <td>22.8</td>\n",
       "      <td>5.7</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>54.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>100.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>207.0</td>\n",
       "      <td>42.74</td>\n",
       "      <td>22.8</td>\n",
       "      <td>5.7</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>65.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>97.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Porto</td>\n",
       "      <td>112.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>81.01</td>\n",
       "      <td>26.3</td>\n",
       "      <td>6.1</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3503</th>\n",
       "      <td>65.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>97.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Porto</td>\n",
       "      <td>112.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>81.01</td>\n",
       "      <td>26.3</td>\n",
       "      <td>6.1</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ambient_humidity  baking_duration  cooling_period  cream_fat_content  \\\n",
       "id                                                                           \n",
       "1                 54.0             24.0            26.0              100.4   \n",
       "1525              54.0             24.0            26.0              100.4   \n",
       "2917              65.0             40.0            49.0               97.5   \n",
       "3503              65.0             40.0            49.0               97.5   \n",
       "\n",
       "      egg_temperature  egg_yolk_count  final_temperature  lemon_zest_ph  \\\n",
       "id                                                                        \n",
       "1                52.0            11.0              309.0            3.2   \n",
       "1525             52.0            11.0              309.0            3.2   \n",
       "2917             30.0            10.0              122.0            3.1   \n",
       "3503             30.0            10.0              122.0            3.1   \n",
       "\n",
       "      origin  oven_temperature  preheating_time  salt_ratio  sugar_content  \\\n",
       "id                                                                           \n",
       "1     Lisboa               NaN            207.0       42.74           22.8   \n",
       "1525  Lisboa               NaN            207.0       42.74           22.8   \n",
       "2917   Porto             112.0            346.0       81.01           26.3   \n",
       "3503   Porto             112.0            346.0       81.01           26.3   \n",
       "\n",
       "      vanilla_extract quality_class  \n",
       "id                                   \n",
       "1                 5.7            KO  \n",
       "1525              5.7            KO  \n",
       "2917              6.1            OK  \n",
       "3503              6.1            OK  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#these two lines check the duplicate rows in the dataset and display them\n",
    "duplicate_rows = dataset_learn[dataset_learn.duplicated(keep=False)]\n",
    "duplicate_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8095c97d",
   "metadata": {},
   "source": [
    "As we can see above, there are two duplicate records. Having two bakeries with exactly the same values in all columns is too much of a coincidence for them to not be duplicates. The next two lines of codes will drop them and display the shape of the modified dataset, where we can see there are less two rows than before (5200 rows before, 5198 now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc59a185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (5198, 15)\n"
     ]
    }
   ],
   "source": [
    "dataset_learn.drop_duplicates(inplace=True)\n",
    "print(f'Shape: {dataset_learn.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a16f829",
   "metadata": {},
   "source": [
    "### **2.4. How to Handle Missing Values**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bc5ba8",
   "metadata": {},
   "source": [
    "We will now deal with all the missing values in our dataset. We chose to treat them before treating the outliers so that we would have a more accurate imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9f9cd65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ambient_humidity      18\n",
       "baking_duration        1\n",
       "cooling_period         1\n",
       "cream_fat_content     24\n",
       "egg_temperature       24\n",
       "egg_yolk_count        24\n",
       "final_temperature     25\n",
       "lemon_zest_ph         26\n",
       "origin               161\n",
       "oven_temperature      20\n",
       "preheating_time       19\n",
       "salt_ratio            13\n",
       "sugar_content         22\n",
       "vanilla_extract       18\n",
       "quality_class          1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_learn.isna().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07263161",
   "metadata": {},
   "source": [
    "### **2.1. How to Handle Outliers**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5d062f",
   "metadata": {},
   "source": [
    "In notebook1, in the box plots in 'Outlier Detection', we observed that all the columns have outliers except for the `ambient_humidity` one, therefore, down below we go column by column and in each one we decided what to do with their respective outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be919762",
   "metadata": {},
   "source": [
    "### Ambient Humidity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4921fc76",
   "metadata": {},
   "source": [
    "As we said before, the `ambient_humidity` variable does not have any outliers, therefore, we do not change anything."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60697bf7",
   "metadata": {},
   "source": [
    "### Baking Duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4333fc0",
   "metadata": {},
   "source": [
    "perguntar ao stor se ele considera estes valores outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_humidity = dataset_learn['baking_duration'].quantile(0.25)\n",
    "Q3_humidity = dataset_learn['baking_duration'].quantile(0.75)\n",
    "IQR_humidity = Q3_humidity - Q1_humidity\n",
    "lower_bound_humidity = Q1_humidity - 1.5 * IQR_humidity\n",
    "upper_bound_humidity = Q3_humidity + 1.5 * IQR_humidity\n",
    "\n",
    "outliers = dataset_learn[(dataset_learn['baking_duration'] < lower_bound_humidity) | (dataset_learn['baking_duration'] > upper_bound_humidity)]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b112eb8",
   "metadata": {},
   "source": [
    "### Cooling Period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68f93c1",
   "metadata": {},
   "source": [
    "perguntar so stor tambem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843cdca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_humidity = dataset_learn['cooling_period'].quantile(0.25)\n",
    "Q3_humidity = dataset_learn['cooling_period'].quantile(0.75)\n",
    "IQR_humidity = Q3_humidity - Q1_humidity\n",
    "lower_bound_humidity = Q1_humidity - 1.5 * IQR_humidity\n",
    "upper_bound_humidity = Q3_humidity + 1.5 * IQR_humidity\n",
    "\n",
    "outliers = dataset_learn[(dataset_learn['cooling_period'] < lower_bound_humidity) | (dataset_learn['cooling_period'] > upper_bound_humidity)]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fab0e39",
   "metadata": {},
   "source": [
    "### Cream Fat Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da1086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_humidity = dataset_learn['cream_fat_content'].quantile(0.25)\n",
    "Q3_humidity = dataset_learn['cream_fat_content'].quantile(0.75)\n",
    "IQR_humidity = Q3_humidity - Q1_humidity\n",
    "lower_bound_humidity = Q1_humidity - 1.5 * IQR_humidity\n",
    "upper_bound_humidity = Q3_humidity + 1.5 * IQR_humidity\n",
    "\n",
    "outliers = dataset_learn[(dataset_learn['cream_fat_content'] < lower_bound_humidity) | (dataset_learn['cream_fat_content'] > upper_bound_humidity)]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9440a496",
   "metadata": {},
   "source": [
    "### Egg Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d754df76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_humidity = dataset_learn['egg_temperature'].quantile(0.25)\n",
    "Q3_humidity = dataset_learn['egg_temperature'].quantile(0.75)\n",
    "IQR_humidity = Q3_humidity - Q1_humidity\n",
    "lower_bound_humidity = Q1_humidity - 1.5 * IQR_humidity\n",
    "upper_bound_humidity = Q3_humidity + 1.5 * IQR_humidity\n",
    "\n",
    "outliers = dataset_learn[(dataset_learn['egg_temperature'] < lower_bound_humidity) | (dataset_learn['egg_temperature'] > upper_bound_humidity)]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdd0d39",
   "metadata": {},
   "source": [
    "### Egg Yolk Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b850226c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_humidity = dataset_learn['egg_yolk_count'].quantile(0.25)\n",
    "Q3_humidity = dataset_learn['egg_yolk_count'].quantile(0.75)\n",
    "IQR_humidity = Q3_humidity - Q1_humidity\n",
    "lower_bound_humidity = Q1_humidity - 1.5 * IQR_humidity\n",
    "upper_bound_humidity = Q3_humidity + 1.5 * IQR_humidity\n",
    "\n",
    "outliers = dataset_learn[(dataset_learn['egg_yolk_count'] < lower_bound_humidity) | (dataset_learn['egg_yolk_count'] > upper_bound_humidity)]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40076378",
   "metadata": {},
   "source": [
    "### Final Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92de8062",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_humidity = dataset_learn['final_temperature'].quantile(0.25)\n",
    "Q3_humidity = dataset_learn['final_temperature'].quantile(0.75)\n",
    "IQR_humidity = Q3_humidity - Q1_humidity\n",
    "lower_bound_humidity = Q1_humidity - 1.5 * IQR_humidity\n",
    "upper_bound_humidity = Q3_humidity + 1.5 * IQR_humidity\n",
    "\n",
    "outliers = dataset_learn[(dataset_learn['final_temperature'] < lower_bound_humidity) | (dataset_learn['final_temperature'] > upper_bound_humidity)]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45255b6c",
   "metadata": {},
   "source": [
    "### Lemon Zest Ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6914fe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_humidity = dataset_learn['lemon_zest_ph'].quantile(0.25)\n",
    "Q3_humidity = dataset_learn['lemon_zest_ph'].quantile(0.75)\n",
    "IQR_humidity = Q3_humidity - Q1_humidity\n",
    "lower_bound_humidity = Q1_humidity - 1.5 * IQR_humidity\n",
    "upper_bound_humidity = Q3_humidity + 1.5 * IQR_humidity\n",
    "\n",
    "outliers = dataset_learn[(dataset_learn['lemon_zest_ph'] < lower_bound_humidity) | (dataset_learn['lemon_zest_ph'] > upper_bound_humidity)]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558e8ae2",
   "metadata": {},
   "source": [
    "### Oven Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d0fe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_temp = dataset_learn['oven_temperature'].quantile(0.25)\n",
    "Q3_temp = dataset_learn['oven_temperature'].quantile(0.75)\n",
    "IQR_temp = Q3_temp - Q1_temp\n",
    "lower_bound_temp = Q1_temp - 1.5 * IQR_temp\n",
    "upper_bound_temp = Q3_temp + 1.5 * IQR_temp\n",
    "outliers = dataset_learn[(dataset_learn['oven_temperature'] < lower_bound_temp) | (dataset_learn['oven_temperature'] > upper_bound_temp)]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e793a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preheating Time Outliers Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854e9acc",
   "metadata": {},
   "source": [
    "### Preheating Time Outliers Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7c293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_pretime = dataset_learn['preheating_time'].quantile(0.25)\n",
    "Q3_pretime = dataset_learn['preheating_time'].quantile(0.75)\n",
    "IQR_pretime = Q3_pretime - Q1_pretime\n",
    "lower_bound_pretime = Q1_pretime - 1.5 * IQR_pretime\n",
    "upper_bound_pretime = Q3_pretime + 1.5 * IQR_pretime\n",
    "outliers = dataset_learn[(dataset_learn['preheating_time'] < lower_bound_pretime) | (dataset_learn['preheating_time'] > upper_bound_pretime)]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0079061f",
   "metadata": {},
   "source": [
    "### Salt Ratio Outliers Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6500b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_salt = dataset_learn['salt_ratio'].quantile(0.25)\n",
    "Q3_salt = dataset_learn['salt_ratio'].quantile(0.75)\n",
    "IQR_salt = Q3_salt - Q1_salt\n",
    "lower_bound_salt = Q1_salt - 1.5 * IQR_salt\n",
    "upper_bound_salt = Q3_salt + 1.5 * IQR_salt\n",
    "outliers = dataset_learn[(dataset_learn['salt_ratio'] < lower_bound_salt) | (dataset_learn['salt_ratio'] > upper_bound_salt)]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e032e849",
   "metadata": {},
   "source": [
    "### Sugar Content Outliears Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff163139",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_sugar = dataset_learn['sugar_content'].quantile(0.25)\n",
    "Q3_sugar = dataset_learn['sugar_content'].quantile(0.75)\n",
    "IQR_sugar = Q3_sugar - Q1_sugar\n",
    "lower_bound_sugar = Q1_sugar - 1.5 * IQR_sugar\n",
    "upper_bound_sugar = Q3_sugar + 1.5 * IQR_sugar\n",
    "outliers = dataset_learn[(dataset_learn['sugar_content'] < lower_bound_sugar) | (dataset_learn['sugar_content'] > upper_bound_sugar)]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d8c7b5",
   "metadata": {},
   "source": [
    "### Vanilla Extract Outliers Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9cc1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_vanilla = dataset_learn['vanilla_extract'].quantile(0.25)\n",
    "Q3_vanilla = dataset_learn['vanilla_extract'].quantile(0.75)\n",
    "IQR_vanilla = Q3_vanilla - Q1_vanilla\n",
    "lower_bound_vanilla = Q1_vanilla - 1.5 * IQR_vanilla\n",
    "upper_bound_vanilla = Q3_vanilla + 1.5 * IQR_vanilla\n",
    "outliers = dataset_learn[(dataset_learn['vanilla_extract'] < lower_bound_vanilla) | (dataset_learn['vanilla_extract'] > upper_bound_vanilla)]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaeef42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
