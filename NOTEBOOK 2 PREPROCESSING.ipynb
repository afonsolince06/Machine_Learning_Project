{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69df1fad",
   "metadata": {},
   "source": [
    "# **Notebook 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4647b6f",
   "metadata": {},
   "source": [
    "## **Table of Contents**\n",
    "\n",
    "* [1. Introduction](#1-introduction)\n",
    "\n",
    "* [2. Importing Section](#2-importing-section)\n",
    "    * [2.1 Importing Libraries](#21-importing-libraries)\n",
    "    * [2.2 Importing the Datasets](#22-importing-the-learn-and-predict-dataset)\n",
    "\n",
    "* [3. Data Cleaning and Handling Inconsistencies](#3-data-cleaning-and-handling-inconsistencies)\n",
    "    * [3.1. Handling Impossible Values](#31-handling-impossible-values.)\n",
    "    * [3.2. Categorical Consistency](#32-categorical-consistency)\n",
    "    * [3.3. Feature Dropping](#33-feature-dropping.)\n",
    "    * [3.4. Data Type Correction](#34-data-type-correction)\n",
    "    * [3.5. Target Variable Encoding](#35-target-variable-encoding)\n",
    "* [4. Feature Engineering](#4-feature-engineering)\n",
    "* [5. Data Partioning](#5-data-partitioning)\n",
    "    * [5.1. Separate Numerical and Categorical](#51-separate-numerical-and-categorical)\n",
    "    * [5.2. Imputation of Missing Values](#52-imputation-of-missing-values)\n",
    "    * [5.3. Encoding Categorical Data](#53-encoding-categorical-features)\n",
    "    * [5.4. Feature Scaling](#54-feature-scaling)\n",
    "* [6. Preparation for Next Steps](#6-prepare-for-feature-selection-and-modelling)\n",
    "* [7. Conclusion](#7-conclusion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c185476f",
   "metadata": {},
   "source": [
    "# **Notebook 2: Data Preprocessing & Feature Engineering**\n",
    "\n",
    "## **1. Introduction**\n",
    "\n",
    "Following the Exploratory Data Analysis in Notebook 1, where we identified the distribution, relationships, and quality issues within the dataset, this notebook focuses on the **Data Preprocessing** phase. \n",
    "\n",
    "Raw data is rarely ready for Machine Learning algorithms, therefore, it requires **cleaning, transformation, and structuring** to ensure model performance.\n",
    "\n",
    "### **Objectives & Our Workflow**\n",
    "\n",
    "1.  **Data Cleaning & Handling Inconsistencies:**\n",
    "    Before any manipulation, we start to handle physical inconsistencies (like impossible percentages), standardizing categorical text (unifying \"LISBOA \" vs. \"lisboa\"), and removing any irrelevant or constant features.\n",
    "\n",
    "2.  **Feature Engineering:**\n",
    "    We create new features such as `baking_intensity` and `sugar_fat_ratio` to try to enhance the predictive power overall\n",
    "\n",
    "3.  **Strict Data Partitioning:**\n",
    "    We split the data into **Train (70%)**, **Validation (15%)**, and **Test (15%)** sets using a stratified approach. This ensures that the class balance (OK vs. KO) is preserved across all partitions.\n",
    "\n",
    "By the end of this notebook, both the labeled dataset (`learn.csv`) and the unlabelled prediction dataset (`predict.csv`) will be fully processed and consolidated, ready for the Feature Selection phase in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9154f0",
   "metadata": {},
   "source": [
    "## **2. Importing Section**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808a0db3",
   "metadata": {},
   "source": [
    "### **2.1. Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9c7cef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle, os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data partitioning\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold \n",
    "\n",
    "# Imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Encoding\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Scaling methods\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "#Machine Learning Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#Model Evaluation Metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "#Feature Selection\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LassoCV\n",
    "import scipy.stats as stats\n",
    "\n",
    "#Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d78be1a",
   "metadata": {},
   "source": [
    "### **2.2. Importing the Learn and Predict Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23c9fa60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ambient_humidity</th>\n",
       "      <th>baking_duration</th>\n",
       "      <th>cooling_period</th>\n",
       "      <th>cream_fat_content</th>\n",
       "      <th>egg_temperature</th>\n",
       "      <th>egg_yolk_count</th>\n",
       "      <th>final_temperature</th>\n",
       "      <th>lemon_zest_ph</th>\n",
       "      <th>notes_baker</th>\n",
       "      <th>origin</th>\n",
       "      <th>oven_temperature</th>\n",
       "      <th>pastry_type</th>\n",
       "      <th>preheating_time</th>\n",
       "      <th>salt_ratio</th>\n",
       "      <th>sugar_content</th>\n",
       "      <th>vanilla_extract</th>\n",
       "      <th>quality_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>100.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pastel Nata</td>\n",
       "      <td>207.0</td>\n",
       "      <td>42.74</td>\n",
       "      <td>22.8</td>\n",
       "      <td>5.7</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>306.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>245.0</td>\n",
       "      <td>41.73</td>\n",
       "      <td>11.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>99.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Porto</td>\n",
       "      <td>121.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186.0</td>\n",
       "      <td>75.10</td>\n",
       "      <td>20.3</td>\n",
       "      <td>7.5</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>357.0</td>\n",
       "      <td>Pastel de Nata</td>\n",
       "      <td>186.0</td>\n",
       "      <td>46.41</td>\n",
       "      <td>73.3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>100.1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>202.0</td>\n",
       "      <td>Pastel de nata</td>\n",
       "      <td>218.0</td>\n",
       "      <td>56.52</td>\n",
       "      <td>80.1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>60.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>222.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>177.0</td>\n",
       "      <td>34.42</td>\n",
       "      <td>58.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5197</th>\n",
       "      <td>61.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>96.4</td>\n",
       "      <td>99.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>366.0</td>\n",
       "      <td>Pastel De Nata</td>\n",
       "      <td>224.0</td>\n",
       "      <td>46.18</td>\n",
       "      <td>141.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5198</th>\n",
       "      <td>69.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>97.7</td>\n",
       "      <td>90.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>203.0</td>\n",
       "      <td>Pastel de nata</td>\n",
       "      <td>158.0</td>\n",
       "      <td>28.46</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5199</th>\n",
       "      <td>70.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>101.2</td>\n",
       "      <td>139.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>391.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>196.0</td>\n",
       "      <td>56.92</td>\n",
       "      <td>188.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5200</th>\n",
       "      <td>54.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>95.8</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>346.0</td>\n",
       "      <td>Pastel de nata</td>\n",
       "      <td>174.0</td>\n",
       "      <td>53.50</td>\n",
       "      <td>17.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5200 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ambient_humidity  baking_duration  cooling_period  cream_fat_content  \\\n",
       "id                                                                           \n",
       "1                 54.0             24.0            26.0              100.4   \n",
       "2                 66.0             37.0            34.0               98.0   \n",
       "3                 41.0             30.0            19.0               99.3   \n",
       "4                 62.0             24.0            48.0               98.0   \n",
       "5                 55.0             21.0            34.0              100.1   \n",
       "...                ...              ...             ...                ...   \n",
       "5196              60.0             18.0            35.0               96.0   \n",
       "5197              61.0             25.0            40.0               96.4   \n",
       "5198              69.0             18.0            36.0               97.7   \n",
       "5199              70.0             25.0            40.0              101.2   \n",
       "5200              54.0             26.0            39.0               95.8   \n",
       "\n",
       "      egg_temperature  egg_yolk_count  final_temperature  lemon_zest_ph  \\\n",
       "id                                                                        \n",
       "1                52.0            11.0              309.0            3.2   \n",
       "2                46.0            10.0              317.0            3.3   \n",
       "3                53.0            10.0              130.0            3.4   \n",
       "4               115.0             9.0              354.0            3.3   \n",
       "5                48.0             9.0              211.0            3.0   \n",
       "...               ...             ...                ...            ...   \n",
       "5196             72.0            11.0              215.0            3.3   \n",
       "5197             99.0             9.0              367.0            3.2   \n",
       "5198             90.0            11.0              206.0            3.6   \n",
       "5199            139.0             9.0              414.0            3.1   \n",
       "5200             36.0            10.0              333.0            3.5   \n",
       "\n",
       "      notes_baker   origin  oven_temperature     pastry_type  preheating_time  \\\n",
       "id                                                                              \n",
       "1             NaN   Lisboa               NaN     Pastel Nata            207.0   \n",
       "2             NaN   Lisboa             306.0             NaN            245.0   \n",
       "3             NaN    Porto             121.0             NaN            186.0   \n",
       "4             NaN   Lisboa             357.0  Pastel de Nata            186.0   \n",
       "5             NaN   Lisboa             202.0  Pastel de nata            218.0   \n",
       "...           ...      ...               ...             ...              ...   \n",
       "5196          NaN  Lisboa              222.0             NaN            177.0   \n",
       "5197          NaN   Lisboa             366.0  Pastel De Nata            224.0   \n",
       "5198          NaN   Lisboa             203.0  Pastel de nata            158.0   \n",
       "5199          NaN   Lisboa             391.0             NaN            196.0   \n",
       "5200          NaN  Lisboa              346.0  Pastel de nata            174.0   \n",
       "\n",
       "      salt_ratio  sugar_content  vanilla_extract quality_class  \n",
       "id                                                              \n",
       "1          42.74           22.8              5.7            KO  \n",
       "2          41.73           11.6              4.0            KO  \n",
       "3          75.10           20.3              7.5            OK  \n",
       "4          46.41           73.3              4.2            OK  \n",
       "5          56.52           80.1              6.0            KO  \n",
       "...          ...            ...              ...           ...  \n",
       "5196       34.42           58.9              5.7            OK  \n",
       "5197       46.18          141.4              6.5            KO  \n",
       "5198       28.46           10.0              6.0            OK  \n",
       "5199       56.92          188.9              5.7            KO  \n",
       "5200       53.50           17.9              4.5            KO  \n",
       "\n",
       "[5200 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_learn = pd.read_csv('Nata_Files/learn.csv', index_col = 0) # index_col = 0 makes the first column of the dataset the index\n",
    "dataset_learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec1cee9",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; The `predict.csv` dataset (unseen data)  needs to go through the same transformations applied previously to the training data. That way, we **guarantee consistency** between all datasets.\n",
    "The Machine Learning model must receive all the datasets with the **same format**: the same columns on the same scales and with the same categorical encodings used during the training phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d006f7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1300, 16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ambient_humidity</th>\n",
       "      <th>baking_duration</th>\n",
       "      <th>cooling_period</th>\n",
       "      <th>cream_fat_content</th>\n",
       "      <th>egg_temperature</th>\n",
       "      <th>egg_yolk_count</th>\n",
       "      <th>final_temperature</th>\n",
       "      <th>lemon_zest_ph</th>\n",
       "      <th>notes_baker</th>\n",
       "      <th>origin</th>\n",
       "      <th>oven_temperature</th>\n",
       "      <th>pastry_type</th>\n",
       "      <th>preheating_time</th>\n",
       "      <th>salt_ratio</th>\n",
       "      <th>sugar_content</th>\n",
       "      <th>vanilla_extract</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5201</th>\n",
       "      <td>79.0</td>\n",
       "      <td>22</td>\n",
       "      <td>40</td>\n",
       "      <td>98.6</td>\n",
       "      <td>79.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>268.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208.0</td>\n",
       "      <td>49.63</td>\n",
       "      <td>182.6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5202</th>\n",
       "      <td>49.0</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>101.9</td>\n",
       "      <td>105.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>287.0</td>\n",
       "      <td>Pastel de nata</td>\n",
       "      <td>189.0</td>\n",
       "      <td>182.54</td>\n",
       "      <td>76.2</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5203</th>\n",
       "      <td>80.0</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>96.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Porto</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Pastel Nata</td>\n",
       "      <td>201.0</td>\n",
       "      <td>100.41</td>\n",
       "      <td>23.5</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>74.0</td>\n",
       "      <td>21</td>\n",
       "      <td>37</td>\n",
       "      <td>97.2</td>\n",
       "      <td>81.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>317.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220.0</td>\n",
       "      <td>46.66</td>\n",
       "      <td>143.2</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5205</th>\n",
       "      <td>41.0</td>\n",
       "      <td>19</td>\n",
       "      <td>41</td>\n",
       "      <td>97.3</td>\n",
       "      <td>104.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>243.0</td>\n",
       "      <td>Pastel Nata</td>\n",
       "      <td>191.0</td>\n",
       "      <td>39.45</td>\n",
       "      <td>143.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>73.0</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>98.9</td>\n",
       "      <td>58.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Pastel De Nata</td>\n",
       "      <td>189.0</td>\n",
       "      <td>37.80</td>\n",
       "      <td>142.6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6497</th>\n",
       "      <td>66.0</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>100.6</td>\n",
       "      <td>62.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>264.0</td>\n",
       "      <td>Pastel de nata</td>\n",
       "      <td>235.0</td>\n",
       "      <td>33.78</td>\n",
       "      <td>102.2</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6498</th>\n",
       "      <td>41.0</td>\n",
       "      <td>49</td>\n",
       "      <td>23</td>\n",
       "      <td>98.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Porto</td>\n",
       "      <td>69.0</td>\n",
       "      <td>Pastel de nata</td>\n",
       "      <td>243.0</td>\n",
       "      <td>86.73</td>\n",
       "      <td>21.3</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6499</th>\n",
       "      <td>42.0</td>\n",
       "      <td>26</td>\n",
       "      <td>54</td>\n",
       "      <td>98.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Porto</td>\n",
       "      <td>115.0</td>\n",
       "      <td>Pastel de Nata</td>\n",
       "      <td>333.0</td>\n",
       "      <td>135.35</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6500</th>\n",
       "      <td>74.0</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "      <td>99.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>233.0</td>\n",
       "      <td>Pastel de Nata</td>\n",
       "      <td>218.0</td>\n",
       "      <td>47.63</td>\n",
       "      <td>132.7</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ambient_humidity  baking_duration  cooling_period  cream_fat_content  \\\n",
       "id                                                                           \n",
       "5201              79.0               22              40               98.6   \n",
       "5202              49.0               26              32              101.9   \n",
       "5203              80.0               28              24               96.6   \n",
       "5204              74.0               21              37               97.2   \n",
       "5205              41.0               19              41               97.3   \n",
       "...                ...              ...             ...                ...   \n",
       "6496              73.0               24              23               98.9   \n",
       "6497              66.0               21              34              100.6   \n",
       "6498              41.0               49              23               98.9   \n",
       "6499              42.0               26              54               98.0   \n",
       "6500              74.0               18              32               99.0   \n",
       "\n",
       "      egg_temperature  egg_yolk_count  final_temperature  lemon_zest_ph  \\\n",
       "id                                                                        \n",
       "5201             79.0             9.0              259.0            3.2   \n",
       "5202            105.0             9.0              287.0            3.2   \n",
       "5203             20.0            10.0               64.0            3.4   \n",
       "5204             81.0             9.0              314.0            3.0   \n",
       "5205            104.0            10.0              246.0            3.2   \n",
       "...               ...             ...                ...            ...   \n",
       "6496             58.0            10.0              208.0            3.1   \n",
       "6497             62.0            10.0              277.0            3.1   \n",
       "6498             20.0            11.0               57.0            3.4   \n",
       "6499             44.0            12.0              135.0            3.4   \n",
       "6500            104.0             9.0              236.0            3.3   \n",
       "\n",
       "      notes_baker  origin  oven_temperature     pastry_type  preheating_time  \\\n",
       "id                                                                             \n",
       "5201          NaN  Lisboa             268.0             NaN            208.0   \n",
       "5202          NaN  Lisboa             287.0  Pastel de nata            189.0   \n",
       "5203          NaN   Porto              74.0     Pastel Nata            201.0   \n",
       "5204          NaN  Lisboa             317.0             NaN            220.0   \n",
       "5205          NaN  Lisboa             243.0     Pastel Nata            191.0   \n",
       "...           ...     ...               ...             ...              ...   \n",
       "6496          NaN  Lisboa             200.0  Pastel De Nata            189.0   \n",
       "6497          NaN  Lisboa             264.0  Pastel de nata            235.0   \n",
       "6498          NaN   Porto              69.0  Pastel de nata            243.0   \n",
       "6499          NaN   Porto             115.0  Pastel de Nata            333.0   \n",
       "6500          NaN  Lisboa             233.0  Pastel de Nata            218.0   \n",
       "\n",
       "      salt_ratio  sugar_content  vanilla_extract  \n",
       "id                                                \n",
       "5201       49.63          182.6              4.0  \n",
       "5202      182.54           76.2              4.8  \n",
       "5203      100.41           23.5              6.1  \n",
       "5204       46.66          143.2              4.9  \n",
       "5205       39.45          143.0              7.0  \n",
       "...          ...            ...              ...  \n",
       "6496       37.80          142.6              4.0  \n",
       "6497       33.78          102.2              4.8  \n",
       "6498       86.73           21.3              7.4  \n",
       "6499      135.35           18.0              7.6  \n",
       "6500       47.63          132.7              3.7  \n",
       "\n",
       "[1300 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Loading the prediction dataset\n",
    "'''\n",
    "predict_data = pd.read_csv('Nata_Files/predict.csv', index_col = 0)\n",
    "display(predict_data.shape)\n",
    "predict_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da16375",
   "metadata": {},
   "source": [
    "## **3. Data Cleaning and Handling Inconsistencies**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e8a18a",
   "metadata": {},
   "source": [
    "### **3.1. Handling Impossible Values**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc647f4c",
   "metadata": {},
   "source": [
    "While analysing our dataset and our features, we found that there were some  **physically impossible values** that can represent data entry errors or sensor malfunctions.\n",
    "\n",
    "Therefore, we defined the following domain constraints:\n",
    "1.  **Percentages (Humidity & Fat):** Must be between 0% and 100%.\n",
    "2.  **pH Scale:** Must be between 0 and 14.\n",
    "3.  **Physical Dimensions (Time/Temp):** Must be non-negative.\n",
    "\n",
    "**Treatment Strategy:**\n",
    "\n",
    "Instead of dropping these rows, as we would lose valuable information, we **convert these 'errors' to `NaN`** (Missing Values). These will be handled later on.\n",
    "\n",
    "**Note:** In cases where values exceeded the constrained limits, capping them at those thresholds would introduce a larger error compared to median imputation. Additionally, capping would create an artificial 'spike' in the data at those thresholds, distorting the feature's distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb869dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impossible Humidity rows in dataset_learn: 0\n",
      "Impossible Humidity rows in predict_data: 0\n",
      "Impossible Fat rows: 1099\n",
      "Impossible Fat rows in predict_data: 281\n",
      "Impossible pH rows: 0\n",
      "Impossible pH rows in predict_data: 0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "In the descriptive statistics of notebook 1, we verified that there were no negative number in the dataset. \n",
    "Therefore, we will not check for impossible values for that constraint.\n",
    "'''\n",
    "# 1st Constraint: Percentages (0 to 100)\n",
    "impossible_humidityL = dataset_learn[(dataset_learn['ambient_humidity'] > 100) | (dataset_learn['ambient_humidity'] < 0)]\n",
    "impossible_fatL = dataset_learn[(dataset_learn['cream_fat_content'] > 100) | (dataset_learn['cream_fat_content'] < 0)]\n",
    "\n",
    "impossible_humidityP = predict_data[(predict_data['ambient_humidity'] > 100) | (predict_data['ambient_humidity'] < 0)]\n",
    "impossible_fatP = predict_data[(predict_data['cream_fat_content'] > 100) | (predict_data['cream_fat_content'] < 0)]\n",
    "\n",
    "# 2nd Constraint: pH Scale (0 to 14)\n",
    "impossible_phL = dataset_learn[(dataset_learn['lemon_zest_ph'] > 14) | (dataset_learn['lemon_zest_ph'] < 0)]\n",
    "impossible_phP = predict_data[(predict_data['lemon_zest_ph'] > 14) | (predict_data['lemon_zest_ph'] < 0)]\n",
    "\n",
    "print(f\"Impossible Humidity rows in dataset_learn: {len(impossible_humidityL)}\")\n",
    "print(f\"Impossible Humidity rows in predict_data: {len(impossible_humidityP)}\")\n",
    "\n",
    "print(f\"Impossible Fat rows in dataset_learn: {len(impossible_fatL)}\")\n",
    "print(f\"Impossible Fat rows in predict_data: {len(impossible_fatP)}\")\n",
    "\n",
    "print(f\"Impossible pH rows in dataset_learn: {len(impossible_phL)}\")\n",
    "print(f\"Impossible pH rows in predict_data: {len(impossible_phP)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40233d1f",
   "metadata": {},
   "source": [
    "From the results obtained we can observe that:\n",
    "- **1099 rows in dataset_learn** and **281 rows in predict_data** have a `cream_fat_content` value **above 100%** which is impossible\n",
    "\n",
    "All these values will be transformed into `NaN` as previously said, and will be later imputed in the imputation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4bf35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We will just replace the values in cream fat content as it is the only feature with impossible values found (in both datasets).\n",
    "'''\n",
    "dataset_learn.loc[impossible_fatL.index, 'cream_fat_content'] = np.nan\n",
    "predict_data.loc[impossible_fatP.index, 'cream_fat_content'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbeee57",
   "metadata": {},
   "source": [
    "### **3.2. Categorical Consistency**\n",
    "We will conduct this beacuse it ensures that all text or nominal values within a **categorical feature column** are **uniform, consistent, and correctly represented.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbfec7c",
   "metadata": {},
   "source": [
    "**As we saw in the first notebook**, the columns `origin`, which keeps track of where the bakery is located (Lisbon or Porto), has a lot of inconsistencies in the names of those cities. 'Lisboa' and 'Porto' are written in a lot of different ways, therefore, we decided to start Notebook 2 deleting those differences, replacing all the values with either 'Lisboa' and 'Porto' written exactly like that.\n",
    "\n",
    "We also have that exact same problem with the column `pastry_type` in which we found many inconsistencies of the same pastry type written differently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca074780",
   "metadata": {},
   "source": [
    "The first step is to make sure that all the values are really the same in those columns. To be able to see the different type of values (and how many times they appear) in a column we use `value_counts()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be5a0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin\n",
      "Lisboa     3486\n",
      "Porto      1167\n",
      "LISBOA      119\n",
      "Lisboa       88\n",
      "lisboa       83\n",
      "PORTO        33\n",
      "Porto        25\n",
      " Lisboa      20\n",
      "porto        15\n",
      " Porto        3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset_learn['origin'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01ec79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lisboa' 'Porto' nan]\n"
     ]
    }
   ],
   "source": [
    "dataset_learn['origin'] = dataset_learn['origin'].str.strip().str.lower().str.title()  #acho que podes pôr só .capitalize() é mais simples\n",
    "\n",
    "predict_data['origin'] = predict_data['origin'].str.strip().str.lower().str.title()\n",
    "\n",
    "print(dataset_learn['origin'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6cbf86",
   "metadata": {},
   "source": [
    "### **3.3. Feature Dropping**\n",
    "Drop columns that are internal identifiers or text notes, as they are not useful for the model.  \n",
    "\n",
    "The value of the ID has no physical or che ical relationship to the quality of the Pastel de Nata.  \n",
    "The column `notes_baker` has 5200 missing values, which means it does not give us any useful information, therefore, we decided to remove it. \\\n",
    " Additionally, the column `pastry_type` is a constant. It does not add any predictive value to our project, so, after checking if there are any values other than 'Pastel de Nata' written in different ways, we will also remove it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7316d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n era suposto droparmos estas features no feature selection?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6979a8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5200 entries, 1 to 5200\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ambient_humidity   5182 non-null   float64\n",
      " 1   baking_duration    5199 non-null   float64\n",
      " 2   cooling_period     5199 non-null   float64\n",
      " 3   cream_fat_content  5176 non-null   float64\n",
      " 4   egg_temperature    5176 non-null   float64\n",
      " 5   egg_yolk_count     5176 non-null   float64\n",
      " 6   final_temperature  5175 non-null   float64\n",
      " 7   lemon_zest_ph      5174 non-null   float64\n",
      " 8   origin             5039 non-null   object \n",
      " 9   oven_temperature   5179 non-null   float64\n",
      " 10  preheating_time    5181 non-null   float64\n",
      " 11  salt_ratio         5187 non-null   float64\n",
      " 12  sugar_content      5178 non-null   float64\n",
      " 13  vanilla_extract    5182 non-null   float64\n",
      " 14  quality_class      5199 non-null   object \n",
      "dtypes: float64(13), object(2)\n",
      "memory usage: 650.0+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset_learn = dataset_learn.drop(columns=['notes_baker', 'pastry_type'])\n",
    "predict_data = predict_data.drop(columns=['notes_baker', 'pastry_type'])\n",
    "dataset_learn.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3d3bf6",
   "metadata": {},
   "source": [
    "Drop rows where the target variable is null, due to reasons, one in the code and one logic. The one in the code is the stratify=y cannot process them, and the logic one is that either the Pastel de Nata is Ok or not Ok, can't be NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40989c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ambient_humidity      18\n",
      "baking_duration        1\n",
      "cooling_period         1\n",
      "cream_fat_content     24\n",
      "egg_temperature       24\n",
      "egg_yolk_count        24\n",
      "final_temperature     25\n",
      "lemon_zest_ph         26\n",
      "origin               161\n",
      "oven_temperature      21\n",
      "preheating_time       19\n",
      "salt_ratio            13\n",
      "sugar_content         22\n",
      "vanilla_extract       18\n",
      "quality_class          1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset_learn.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49ec49b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_learn = dataset_learn.dropna(subset=['quality_class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b1eafb",
   "metadata": {},
   "source": [
    "### **3.4. Data Type Correction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2343d6",
   "metadata": {},
   "source": [
    "The 'egg_yolk_count' is a count, implying an integer, but often loaded as a float due to NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0d0b8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ambient_humidity</th>\n",
       "      <th>baking_duration</th>\n",
       "      <th>cooling_period</th>\n",
       "      <th>cream_fat_content</th>\n",
       "      <th>egg_temperature</th>\n",
       "      <th>egg_yolk_count</th>\n",
       "      <th>final_temperature</th>\n",
       "      <th>lemon_zest_ph</th>\n",
       "      <th>origin</th>\n",
       "      <th>oven_temperature</th>\n",
       "      <th>preheating_time</th>\n",
       "      <th>salt_ratio</th>\n",
       "      <th>sugar_content</th>\n",
       "      <th>vanilla_extract</th>\n",
       "      <th>quality_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>100.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>11</td>\n",
       "      <td>309.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>207.0</td>\n",
       "      <td>42.74</td>\n",
       "      <td>22.8</td>\n",
       "      <td>5.7</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ambient_humidity  baking_duration  cooling_period  cream_fat_content  \\\n",
       "id                                                                         \n",
       "1               54.0             24.0            26.0              100.4   \n",
       "\n",
       "    egg_temperature  egg_yolk_count  final_temperature  lemon_zest_ph  origin  \\\n",
       "id                                                                              \n",
       "1              52.0              11              309.0            3.2  Lisboa   \n",
       "\n",
       "    oven_temperature  preheating_time  salt_ratio  sugar_content  \\\n",
       "id                                                                 \n",
       "1                NaN            207.0       42.74           22.8   \n",
       "\n",
       "    vanilla_extract quality_class  \n",
       "id                                 \n",
       "1               5.7            KO  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_learn.loc[:, 'egg_yolk_count'] = dataset_learn['egg_yolk_count'].astype('Int64')\n",
    "dataset_learn.head(1) #just to check if the changes were applied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549fadce",
   "metadata": {},
   "source": [
    "### **3.5. Target Variable Encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f2f3f3",
   "metadata": {},
   "source": [
    "The target variable `quality_class` is categorical ('OK' or 'KO'). To better prepare the data for the binary classification models (which is the case), it is necessary to transform it into a binary variable, which means either '0' or '1'.  \n",
    "\n",
    "We decided to attribute:\n",
    "- **1** for \"OK\", the Pastel de Nata is in a good state.\n",
    "- **0** for \"KO\", you should not eat the Pastel de Nata.\n",
    "\n",
    "The \"OK\" class is positive and is the one that will be predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d6d6f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ambient_humidity</th>\n",
       "      <th>baking_duration</th>\n",
       "      <th>cooling_period</th>\n",
       "      <th>cream_fat_content</th>\n",
       "      <th>egg_temperature</th>\n",
       "      <th>egg_yolk_count</th>\n",
       "      <th>final_temperature</th>\n",
       "      <th>lemon_zest_ph</th>\n",
       "      <th>origin</th>\n",
       "      <th>oven_temperature</th>\n",
       "      <th>preheating_time</th>\n",
       "      <th>salt_ratio</th>\n",
       "      <th>sugar_content</th>\n",
       "      <th>vanilla_extract</th>\n",
       "      <th>quality_class_binary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>100.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>11</td>\n",
       "      <td>309.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>207.0</td>\n",
       "      <td>42.74</td>\n",
       "      <td>22.8</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ambient_humidity  baking_duration  cooling_period  cream_fat_content  \\\n",
       "id                                                                         \n",
       "1               54.0             24.0            26.0              100.4   \n",
       "\n",
       "    egg_temperature  egg_yolk_count  final_temperature  lemon_zest_ph  origin  \\\n",
       "id                                                                              \n",
       "1              52.0              11              309.0            3.2  Lisboa   \n",
       "\n",
       "    oven_temperature  preheating_time  salt_ratio  sugar_content  \\\n",
       "id                                                                 \n",
       "1                NaN            207.0       42.74           22.8   \n",
       "\n",
       "    vanilla_extract  quality_class_binary  \n",
       "id                                         \n",
       "1               5.7                     0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_learn['quality_class_binary'] = dataset_learn['quality_class'].replace({'OK': 1, 'KO': 0})\n",
    "dataset_learn = dataset_learn.drop(columns=['quality_class'])\n",
    "dataset_learn.head(1) #just to check if the changes were applied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700a25e2",
   "metadata": {},
   "source": [
    "## **4. Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b5f1ab",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;To better capture the interaction between ingredients and the baking process, we decided to **create two new features**.\n",
    "\n",
    "* **`sugar_fat_ratio`**:\n",
    "    This captures the relative proportion of two key ingredients: `sugar_content` and `cream_fat_content`. A small constant ($1e^{-6}$) was added to prevent errors due to divison by zero in cases where fat content might be zero or missing. \n",
    "\n",
    "    \n",
    "* **`baking_intensity`**:\n",
    "    By multiplying `baking_duration` by `oven_temperature`, we are able to quantify the overall heat exposure the product underwent during the baking process. This allows the model to dstinguish between a 'short but high' heat and a 'long but low' heat.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c03a29d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''These transformations were applied consistently to both the training and prediction datasets, for the reasons already stated.'''\n",
    "\n",
    "#Original Dataset\n",
    "dataset_learn['sugar_fat_ratio'] = dataset_learn['sugar_content'] / (dataset_learn['cream_fat_content'] + 1e-6)  # the small constant to avoid division by zero\n",
    "dataset_learn['baking_intensity'] = dataset_learn['baking_duration'] * dataset_learn['oven_temperature']\n",
    "\n",
    "#Predict Dataset\n",
    "predict_data['sugar_fat_ratio'] = predict_data['sugar_content'] / (predict_data['cream_fat_content'] + 1e-6)\n",
    "predict_data['baking_intensity'] = predict_data['baking_duration'] * predict_data['oven_temperature']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e58ec9",
   "metadata": {},
   "source": [
    "## **5. Data Partitioning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce694ff",
   "metadata": {},
   "source": [
    "In this section, we basically separate the **features (X)** from the **target variable (Y)** and split the dataset into **3 different subsets**. We opted for a Train-Validation-Test split rather than a simple Train-Test split to avoid **Data Leakage** during model optimization.\n",
    "\n",
    "Since `scikit-learn` does not support a 3-way split, we performed two different splits to achieve a **70% / 15% / 15%** distribution:\n",
    "1. **First Split:** We divided the data into **Training (70%)** and a temporary \"Rest\" set (30%).\n",
    "2.  **Second Split:** We split the \"Rest\" set equally (50/50) to create the **Validation (15%)** and **Test (15%)** sets.\n",
    "\n",
    "**Parameters Used:**\n",
    "* `stratify=y`: Ensures the proportion of 'OK' and 'KO' Pastéis de Nata is identical across all three sets.\n",
    "* `random_state=42`: Guarantees reproducibility of the split.\n",
    "* `shuffle = True`: It mixes the rows randomly before cutting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "202de971",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_learn.drop('quality_class_binary',axis = 1) #features\n",
    "y = dataset_learn['quality_class_binary'] #target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b2f46de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_rest, y_train, y_rest = train_test_split(X, y, train_size = 0.7,shuffle = True, random_state=42, stratify=y) #70% train, 30% rest\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_rest, y_rest, test_size=0.5, shuffle = True, random_state=42, stratify=y_rest) #15% val, 15% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dfe75a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.7% | validation:0.15% | test:0.15%\n"
     ]
    }
   ],
   "source": [
    "print('train:{}% | validation:{}% | test:{}%'.format(round(len(y_train)/len(y),2),\n",
    "                                                     round(len(y_val)/len(y),2),\n",
    "                                                     round(len(y_test)/len(y),2)\n",
    "                                                    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57174e34",
   "metadata": {},
   "source": [
    "### **5.1. Separate Numerical and Categorical**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec079dfc",
   "metadata": {},
   "source": [
    "As different data types requires different and specific trasnformations, we separated them into **Numeric** and **Categorical**. We applied this separation consistently across all partitions (Train, Validation, Test) and also the unlabelled Prediction set (`predict_data`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "375f5d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = X.select_dtypes(include = np.number).columns.tolist()\n",
    "categorical_features = X.select_dtypes(exclude = np.number).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "302b67ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Features: ['ambient_humidity', 'baking_duration', 'cooling_period', 'cream_fat_content', 'egg_temperature', 'egg_yolk_count', 'final_temperature', 'lemon_zest_ph', 'oven_temperature', 'preheating_time', 'salt_ratio', 'sugar_content', 'vanilla_extract', 'sugar_fat_ratio', 'baking_intensity']\n",
      "Categorical Features: ['origin']\n"
     ]
    }
   ],
   "source": [
    "print(\"Numerical Features:\", numerical_features)\n",
    "print(\"Categorical Features:\", categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00516485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUMERICAL FEATURES\n",
    "X_train_num = X_train.select_dtypes(include = np.number)\n",
    "X_val_num = X_val.select_dtypes(include = np.number)\n",
    "X_test_num = X_test.select_dtypes(include = np.number)\n",
    "\n",
    "X_predict_num = predict_data.select_dtypes(include = np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81a62b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CATEGORICAL FEATURES\n",
    "X_train_cat = X_train.select_dtypes(exclude = np.number)\n",
    "X_val_cat = X_val.select_dtypes(exclude = np.number)\n",
    "X_test_cat = X_test.select_dtypes(exclude = np.number)\n",
    "\n",
    "X_predict_cat = predict_data.select_dtypes(exclude = np.number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b023d37",
   "metadata": {},
   "source": [
    "### **5.2. Imputation of Missing Values**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411fc1d4",
   "metadata": {},
   "source": [
    "To address missing values (including the \"impossible\" values converted to `NaN` during the cleaning phase), we implemented a **Median Imputation** strategy for the numerical and a **Mode Imputation** to the categorical. We chose the **median over the mean** because it provides a more representative central value as it is **robust to outliers**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfc81f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SimpleImputer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing_values',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">missing_values&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">strategy&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;most_frequent&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fill_value',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fill_value&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">copy&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('add_indicator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">add_indicator&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('keep_empty_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">keep_empty_features&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "SimpleImputer(strategy='most_frequent')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The imputer was fitted only on the training set to prevent Data Leakage\n",
    "This strictly ensures that no information from the evaluation sets leaks into the training process.\n",
    "'''\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "imputer.fit(X_train_num)\n",
    "\n",
    "imputer2 = SimpleImputer(strategy='most_frequent')\n",
    "imputer2.fit(X_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ddf9731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUMERICAL FEATURES\n",
    "#  Transform all splits using the median learned from the training data\n",
    "X_train_num.loc[:, :] = imputer.transform(X_train_num) \n",
    "X_val_num.loc[:, :] = imputer.transform(X_val_num)\n",
    "X_test_num.loc[:, :] = imputer.transform(X_test_num)\n",
    "\n",
    "X_predict_num.loc[:, :] = imputer.transform(X_predict_num)\n",
    "\n",
    "#CATEGORICAL FEATURES\n",
    "#  Transform all splits using the most frequent value learned from the training data\n",
    "X_train_cat.loc[:, :] = imputer2.transform(X_train_cat)\n",
    "X_val_cat.loc[:, :] = imputer2.transform(X_val_cat)\n",
    "X_test_cat.loc[:, :] = imputer2.transform(X_test_cat)   \n",
    "\n",
    "X_predict_cat.loc[:, :] = imputer2.transform(X_predict_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d84fd6f",
   "metadata": {},
   "source": [
    "### **5.3. Encoding Categorical Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7325e9",
   "metadata": {},
   "source": [
    "We utilized the `OneHotEncoder` to transform **categorical data into a machine readable format**. We created binary columns for each category (e.g. `origin_Lisboa`, `origin_Porto`)\n",
    "\n",
    "**Parameters Used:**\n",
    "- `handle_unknown ='ignore'`:  If the Test or Prediction set contains a category label **never seen** during training, the encoder will output **zero** instead of crashing.\n",
    "- `sparse_output= False`: it forces the encoder to return a format that can easily be transformed in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2b7a043",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False) \n",
    "#if an unseen category appears in the test or prediction data, the encoder will ignore it.\n",
    "\n",
    "encoder.fit(X_train_cat) #Once again, only fitting on training data to avoid Data Leakage\n",
    "\n",
    "#Training Data\n",
    "X_train_cat_encoded = encoder.transform(X_train_cat)\n",
    "X_train_cat_encoded = pd.DataFrame(X_train_cat_encoded, columns = encoder.get_feature_names_out(categorical_features), index = X_train_cat.index)\n",
    "\n",
    "#Validation Data\n",
    "X_val_cat_encoded = encoder.transform(X_val_cat)\n",
    "X_val_cat_encoded = pd.DataFrame(X_val_cat_encoded, columns = encoder.get_feature_names_out(categorical_features), index = X_val_cat.index)\n",
    "\n",
    "#Testing Data\n",
    "X_test_cat_encoded = encoder.transform(X_test_cat)  \n",
    "X_test_cat_encoded = pd.DataFrame(X_test_cat_encoded, columns = encoder.get_feature_names_out(categorical_features), index = X_test_cat.index)\n",
    "\n",
    "#Prediction Data\n",
    "X_predict_cat_encoded = encoder.transform(X_predict_cat)\n",
    "X_predict_cat_encoded = pd.DataFrame(X_predict_cat_encoded, columns = encoder.get_feature_names_out(categorical_features), index = X_predict_cat.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741ad3c9",
   "metadata": {},
   "source": [
    "### **5.4. Feature Scaling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ba3daf",
   "metadata": {},
   "source": [
    "Since our dataset has outliers, we chose **RobustScaler** which ensures that the majority of our data is scaled to a standard range without being distorted by the few extreme values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c496f18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The RobustScaler scales the data using the Median and the Interquartile Range (IQR). \n",
    "It subtracts the median and divides by the IQR (75th percentile - 25th percentile). \n",
    "This centers the data and scales it based on the bulk of the data points, effectively ignoring the influence of extreme outliers.\n",
    "\"\"\"\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "\n",
    "#Fitting the scaler ONLY on the training data\n",
    "scaler.fit(X_train_num)\n",
    "\n",
    "#Transforming training data\n",
    "X_train_scaled = scaler.transform(X_train_num)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns = numerical_features, index = X_train_num.index)\n",
    "\n",
    "#Transforming validation data\n",
    "X_val_scaled = scaler.transform(X_val_num)\n",
    "X_val_scaled = pd.DataFrame(X_val_scaled, columns = numerical_features, index = X_val_num.index)\n",
    "\n",
    "#Transforming testing data\n",
    "X_test_scaled = scaler.transform(X_test_num)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns = numerical_features, index = X_test_num.index)\n",
    "\n",
    "#Transforming prediction data\n",
    "X_predict_scaled = scaler.transform(X_predict_num[numerical_features])\n",
    "X_predict_scaled = pd.DataFrame(X_predict_scaled, columns = numerical_features, index = X_predict_num.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaef4379",
   "metadata": {},
   "source": [
    "## **6. Prepare for Feature Selection and Modelling and Saving Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ccc7e7",
   "metadata": {},
   "source": [
    "To prepare for **Feature Selection and Modeling**, we merged the processed numerical and categorical features into a unified dataset. \n",
    "\n",
    "In the Feature Selection part we must have a view of how **ALL** the variables are related to each other and how important to the classification they are. Models like Lasso and RFE do not choose the 'best numerical' or 'best categorical' in isolation but instead in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b3e5b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here we concatenate the scaled numerical features with the encoded categorical features to get the final sets\n",
    "\"\"\"\n",
    "\n",
    "#TRAIN\n",
    "X_train_final = pd.concat([X_train_scaled, X_train_cat_encoded], axis=1)\n",
    "\n",
    "#VALIDATION\n",
    "X_val_final = pd.concat([X_val_scaled, X_val_cat_encoded], axis=1)\n",
    "\n",
    "#TEST\n",
    "X_test_final = pd.concat([X_test_scaled, X_test_cat_encoded], axis=1)\n",
    "\n",
    "#PREDICTION\n",
    "X_predict_final = pd.concat([X_predict_scaled, X_predict_cat_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eacf27",
   "metadata": {},
   "source": [
    "explicar aqui o pickle e ver se isso ta bem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06846cc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Dictionary containing all the arrays/dataframes we need for the next steps\u001b[39;00m\n\u001b[32m      5\u001b[39m processed_data = {\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mX_train_final\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mX_train_final\u001b[49m,\n\u001b[32m      7\u001b[39m     \u001b[33m'\u001b[39m\u001b[33my_train\u001b[39m\u001b[33m'\u001b[39m: y_train,\n\u001b[32m      8\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mX_val_final\u001b[39m\u001b[33m'\u001b[39m: X_val_final,\n\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33my_val\u001b[39m\u001b[33m'\u001b[39m: y_val,\n\u001b[32m     10\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mX_test_final\u001b[39m\u001b[33m'\u001b[39m: X_test_final,\n\u001b[32m     11\u001b[39m     \u001b[33m'\u001b[39m\u001b[33my_test\u001b[39m\u001b[33m'\u001b[39m: y_test,\n\u001b[32m     12\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mX_predict_final\u001b[39m\u001b[33m'\u001b[39m: X_predict_final,\n\u001b[32m     13\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mid_predict\u001b[39m\u001b[33m'\u001b[39m: predict_data.index \u001b[38;5;66;03m# Keeping IDs for the final submission\u001b[39;00m\n\u001b[32m     14\u001b[39m }\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Save to a pickle file (preserves formatting better than CSV)\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mNata_Files/processed_data.pkl\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train_final' is not defined"
     ]
    }
   ],
   "source": [
    "# 6.2 Saving the Processed Datasets\n",
    "import pickle\n",
    "\n",
    "# Dictionary containing all the arrays/dataframes we need for the next steps\n",
    "processed_data = {\n",
    "    'X_train_final': X_train_final,\n",
    "    'y_train': y_train,\n",
    "    'X_val_final': X_val_final,\n",
    "    'y_val': y_val,\n",
    "    'X_test_final': X_test_final,\n",
    "    'y_test': y_test,\n",
    "    'X_predict_final': X_predict_final,\n",
    "    'id_predict': predict_data.index # Keeping IDs for the final submission\n",
    "}\n",
    "\n",
    "# Save to a pickle file (preserves formatting better than CSV)\n",
    "with open('Nata_Files/processed_data.pkl', 'wb') as f:\n",
    "    pickle.dump(processed_data, f)\n",
    "\n",
    "print(\"Data successfully saved to 'Nata_Files/processed_data.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb49666",
   "metadata": {},
   "source": [
    "## **7. Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd5633b",
   "metadata": {},
   "source": [
    "escrever conclusao"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
