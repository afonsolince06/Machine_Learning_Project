{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0edf0d0e",
   "metadata": {},
   "source": [
    "# **Notebook 2**\n",
    "## **Preprocessing**\n",
    "### Introduction\n",
    "The primary goal of this stage is to refine the raw data, transforming it from its initial state into a structurally sound format suitable for feature engineering and modeling.  \n",
    "The objective here s strictly on structural, row-by-row cleaning. This includes:\n",
    "- Handling Irrelevant Features\n",
    "- Target Encoding\n",
    "- Data Type Standardization\n",
    "- Categorical Consistency\n",
    "\n",
    "To ensure no data leakage occurs into the validation or test sets, this notebook avoids any transformation that relies on calculating statistics from the entire dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d923a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fc3b4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ambient_humidity</th>\n",
       "      <th>baking_duration</th>\n",
       "      <th>cooling_period</th>\n",
       "      <th>cream_fat_content</th>\n",
       "      <th>egg_temperature</th>\n",
       "      <th>egg_yolk_count</th>\n",
       "      <th>final_temperature</th>\n",
       "      <th>lemon_zest_ph</th>\n",
       "      <th>notes_baker</th>\n",
       "      <th>origin</th>\n",
       "      <th>oven_temperature</th>\n",
       "      <th>pastry_type</th>\n",
       "      <th>preheating_time</th>\n",
       "      <th>salt_ratio</th>\n",
       "      <th>sugar_content</th>\n",
       "      <th>vanilla_extract</th>\n",
       "      <th>quality_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>100.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pastel Nata</td>\n",
       "      <td>207.0</td>\n",
       "      <td>42.74</td>\n",
       "      <td>22.8</td>\n",
       "      <td>5.7</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>306.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>245.0</td>\n",
       "      <td>41.73</td>\n",
       "      <td>11.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>99.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Porto</td>\n",
       "      <td>121.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186.0</td>\n",
       "      <td>75.10</td>\n",
       "      <td>20.3</td>\n",
       "      <td>7.5</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>357.0</td>\n",
       "      <td>Pastel de Nata</td>\n",
       "      <td>186.0</td>\n",
       "      <td>46.41</td>\n",
       "      <td>73.3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>100.1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>202.0</td>\n",
       "      <td>Pastel de nata</td>\n",
       "      <td>218.0</td>\n",
       "      <td>56.52</td>\n",
       "      <td>80.1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>60.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>222.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>177.0</td>\n",
       "      <td>34.42</td>\n",
       "      <td>58.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5197</th>\n",
       "      <td>61.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>96.4</td>\n",
       "      <td>99.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>366.0</td>\n",
       "      <td>Pastel De Nata</td>\n",
       "      <td>224.0</td>\n",
       "      <td>46.18</td>\n",
       "      <td>141.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5198</th>\n",
       "      <td>69.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>97.7</td>\n",
       "      <td>90.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>203.0</td>\n",
       "      <td>Pastel de nata</td>\n",
       "      <td>158.0</td>\n",
       "      <td>28.46</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5199</th>\n",
       "      <td>70.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>101.2</td>\n",
       "      <td>139.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>391.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>196.0</td>\n",
       "      <td>56.92</td>\n",
       "      <td>188.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5200</th>\n",
       "      <td>54.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>95.8</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>346.0</td>\n",
       "      <td>Pastel de nata</td>\n",
       "      <td>174.0</td>\n",
       "      <td>53.50</td>\n",
       "      <td>17.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5200 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ambient_humidity  baking_duration  cooling_period  cream_fat_content  \\\n",
       "id                                                                           \n",
       "1                 54.0             24.0            26.0              100.4   \n",
       "2                 66.0             37.0            34.0               98.0   \n",
       "3                 41.0             30.0            19.0               99.3   \n",
       "4                 62.0             24.0            48.0               98.0   \n",
       "5                 55.0             21.0            34.0              100.1   \n",
       "...                ...              ...             ...                ...   \n",
       "5196              60.0             18.0            35.0               96.0   \n",
       "5197              61.0             25.0            40.0               96.4   \n",
       "5198              69.0             18.0            36.0               97.7   \n",
       "5199              70.0             25.0            40.0              101.2   \n",
       "5200              54.0             26.0            39.0               95.8   \n",
       "\n",
       "      egg_temperature  egg_yolk_count  final_temperature  lemon_zest_ph  \\\n",
       "id                                                                        \n",
       "1                52.0            11.0              309.0            3.2   \n",
       "2                46.0            10.0              317.0            3.3   \n",
       "3                53.0            10.0              130.0            3.4   \n",
       "4               115.0             9.0              354.0            3.3   \n",
       "5                48.0             9.0              211.0            3.0   \n",
       "...               ...             ...                ...            ...   \n",
       "5196             72.0            11.0              215.0            3.3   \n",
       "5197             99.0             9.0              367.0            3.2   \n",
       "5198             90.0            11.0              206.0            3.6   \n",
       "5199            139.0             9.0              414.0            3.1   \n",
       "5200             36.0            10.0              333.0            3.5   \n",
       "\n",
       "      notes_baker   origin  oven_temperature     pastry_type  preheating_time  \\\n",
       "id                                                                              \n",
       "1             NaN   Lisboa               NaN     Pastel Nata            207.0   \n",
       "2             NaN   Lisboa             306.0             NaN            245.0   \n",
       "3             NaN    Porto             121.0             NaN            186.0   \n",
       "4             NaN   Lisboa             357.0  Pastel de Nata            186.0   \n",
       "5             NaN   Lisboa             202.0  Pastel de nata            218.0   \n",
       "...           ...      ...               ...             ...              ...   \n",
       "5196          NaN  Lisboa              222.0             NaN            177.0   \n",
       "5197          NaN   Lisboa             366.0  Pastel De Nata            224.0   \n",
       "5198          NaN   Lisboa             203.0  Pastel de nata            158.0   \n",
       "5199          NaN   Lisboa             391.0             NaN            196.0   \n",
       "5200          NaN  Lisboa              346.0  Pastel de nata            174.0   \n",
       "\n",
       "      salt_ratio  sugar_content  vanilla_extract quality_class  \n",
       "id                                                              \n",
       "1          42.74           22.8              5.7            KO  \n",
       "2          41.73           11.6              4.0            KO  \n",
       "3          75.10           20.3              7.5            OK  \n",
       "4          46.41           73.3              4.2            OK  \n",
       "5          56.52           80.1              6.0            KO  \n",
       "...          ...            ...              ...           ...  \n",
       "5196       34.42           58.9              5.7            OK  \n",
       "5197       46.18          141.4              6.5            KO  \n",
       "5198       28.46           10.0              6.0            OK  \n",
       "5199       56.92          188.9              5.7            KO  \n",
       "5200       53.50           17.9              4.5            KO  \n",
       "\n",
       "[5200 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_learn = pd.read_csv('Nata_Files/learn.csv', index_col = 0)\n",
    "dataset_learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26fb127",
   "metadata": {},
   "source": [
    "#### **2.1 Feature Dropping**\n",
    "Drop columns that are internal identifiers or text notes, as they are not useful for the model.  \n",
    "\n",
    "The value of the ID has no physical or che ical relationship to the quality of the Pastel de Nata.  \n",
    "The column `notes_baker` has 5200 missing values, which means it does not give us any useful information, therefore, we decided to remove it. \\\n",
    " Additionally, the column `pastry_type` is a constant. It does not add any predictive value to our project, so, after checking if there are any values other than 'Pastel de Nata' written in different ways, we will also remove it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4c3390c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pastry_type\n",
      "NaN               1789\n",
      "Pastel Nata        879\n",
      "Pastel de Nata     859\n",
      "Pastel de nata     840\n",
      "Pastel De Nata     833\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset_learn['pastry_type'].value_counts(dropna=False))\n",
    "#just so we can make sure that all the values in pastry type represent the exact same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1747d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5200 entries, 1 to 5200\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ambient_humidity   5182 non-null   float64\n",
      " 1   baking_duration    5199 non-null   float64\n",
      " 2   cooling_period     5199 non-null   float64\n",
      " 3   cream_fat_content  5176 non-null   float64\n",
      " 4   egg_temperature    5176 non-null   float64\n",
      " 5   egg_yolk_count     5176 non-null   float64\n",
      " 6   final_temperature  5175 non-null   float64\n",
      " 7   lemon_zest_ph      5174 non-null   float64\n",
      " 8   origin             5039 non-null   object \n",
      " 9   oven_temperature   5179 non-null   float64\n",
      " 10  preheating_time    5181 non-null   float64\n",
      " 11  salt_ratio         5187 non-null   float64\n",
      " 12  sugar_content      5178 non-null   float64\n",
      " 13  vanilla_extract    5182 non-null   float64\n",
      " 14  quality_class      5199 non-null   object \n",
      "dtypes: float64(13), object(2)\n",
      "memory usage: 650.0+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset_learn = dataset_learn.drop(columns=['notes_baker','pastry_type'])\n",
    "dataset_learn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715e76f6",
   "metadata": {},
   "source": [
    "Drop rows where the target variable is null, due to reasons, one in the code and one logic. The one in the code is the stratify=y cannot process them, and the logic one is that either the Pastel de Nata is Ok or not Ok, can't be NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9dfa852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ambient_humidity      18\n",
       "baking_duration        1\n",
       "cooling_period         1\n",
       "cream_fat_content     24\n",
       "egg_temperature       24\n",
       "egg_yolk_count        24\n",
       "final_temperature     25\n",
       "lemon_zest_ph         26\n",
       "origin               161\n",
       "oven_temperature      21\n",
       "preheating_time       19\n",
       "salt_ratio            13\n",
       "sugar_content         22\n",
       "vanilla_extract       18\n",
       "quality_class          1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_learn.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a8c3371",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_learn = dataset_learn.dropna(subset=['quality_class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ae88fd",
   "metadata": {},
   "source": [
    "#### **2.2 Categorical Consistnecy and Standarization**\n",
    "We will conduct this to beacuse ensures that all text or nominal values within a categorical feature column are uniform, consistent, and correctly represented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44790a37",
   "metadata": {},
   "source": [
    "As we saw in the first notebook, the column `origin`, which keeps track of where the bakery is located (Lisbon or Porto), has a lot of inconsistencies in the names of those cities. 'Lisboa' and 'Porto' are written in a lot of different ways, therefore, we decided to start Notebook 2 deleting those differences, replacing all the values with either 'Lisboa' and 'Porto' written exactly in like that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea18ab0",
   "metadata": {},
   "source": [
    "# **PERCEBER SE É PARA FAZER ENCODING DISTO PARA 1 E 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07a019b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Lisboa', 'Porto', nan], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_learn['origin'] = dataset_learn['origin'].str.strip().str.lower().str.title()\n",
    "dataset_learn['origin'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50fbcdb",
   "metadata": {},
   "source": [
    "##### **2.3 Data Type Correction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a901da4d",
   "metadata": {},
   "source": [
    "The 'egg_yolk_count' is a count, implying an integer, but often loaded as a float due to NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4251c862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiago\\AppData\\Local\\Temp\\ipykernel_5408\\4017166526.py:1: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '<IntegerArray>\n",
      "[11, 10, 10,  9,  9,  9,  9, 13,  9, 11,\n",
      " ...\n",
      "  9, 11, 11, 13, 12, 11,  9, 11,  9, 10]\n",
      "Length: 5199, dtype: Int64' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  dataset_learn.loc[:, 'egg_yolk_count'] = dataset_learn['egg_yolk_count'].astype('Int64')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ambient_humidity</th>\n",
       "      <th>baking_duration</th>\n",
       "      <th>cooling_period</th>\n",
       "      <th>cream_fat_content</th>\n",
       "      <th>egg_temperature</th>\n",
       "      <th>egg_yolk_count</th>\n",
       "      <th>final_temperature</th>\n",
       "      <th>lemon_zest_ph</th>\n",
       "      <th>origin</th>\n",
       "      <th>oven_temperature</th>\n",
       "      <th>preheating_time</th>\n",
       "      <th>salt_ratio</th>\n",
       "      <th>sugar_content</th>\n",
       "      <th>vanilla_extract</th>\n",
       "      <th>quality_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>100.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>11</td>\n",
       "      <td>309.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>207.0</td>\n",
       "      <td>42.74</td>\n",
       "      <td>22.8</td>\n",
       "      <td>5.7</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ambient_humidity  baking_duration  cooling_period  cream_fat_content  \\\n",
       "id                                                                         \n",
       "1               54.0             24.0            26.0              100.4   \n",
       "\n",
       "    egg_temperature  egg_yolk_count  final_temperature  lemon_zest_ph  origin  \\\n",
       "id                                                                              \n",
       "1              52.0              11              309.0            3.2  Lisboa   \n",
       "\n",
       "    oven_temperature  preheating_time  salt_ratio  sugar_content  \\\n",
       "id                                                                 \n",
       "1                NaN            207.0       42.74           22.8   \n",
       "\n",
       "    vanilla_extract quality_class  \n",
       "id                                 \n",
       "1               5.7            KO  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_learn.loc[:, 'egg_yolk_count'] = dataset_learn['egg_yolk_count'].astype('Int64')\n",
    "dataset_learn.head(1) #just to check if the changes were applied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7870dc",
   "metadata": {},
   "source": [
    "##### **2.4 Target Variable Encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94787e54",
   "metadata": {},
   "source": [
    "The target variable `quality_class` is categorical ('OK' or 'KO'). To better prepare the data for the binary classification models (which is the case), it is necessary to transform it into a binary variable, which means either '0' or '1'.  \n",
    "\n",
    "We decided to attribute:\n",
    "- **1** for \"OK\", the Pastel de Nata is in a good state.\n",
    "- **0** for \"KO\", you should not eat the Pastel de Nata.\n",
    "\n",
    "The \"OK\" class is positive and is the one that will be predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c43899b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiago\\AppData\\Local\\Temp\\ipykernel_5408\\3273873101.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset_learn['quality_class_binary'] = dataset_learn['quality_class'].replace({'OK': 1, 'KO': 0})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ambient_humidity</th>\n",
       "      <th>baking_duration</th>\n",
       "      <th>cooling_period</th>\n",
       "      <th>cream_fat_content</th>\n",
       "      <th>egg_temperature</th>\n",
       "      <th>egg_yolk_count</th>\n",
       "      <th>final_temperature</th>\n",
       "      <th>lemon_zest_ph</th>\n",
       "      <th>origin</th>\n",
       "      <th>oven_temperature</th>\n",
       "      <th>preheating_time</th>\n",
       "      <th>salt_ratio</th>\n",
       "      <th>sugar_content</th>\n",
       "      <th>vanilla_extract</th>\n",
       "      <th>quality_class_binary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>100.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>11</td>\n",
       "      <td>309.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>207.0</td>\n",
       "      <td>42.74</td>\n",
       "      <td>22.8</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ambient_humidity  baking_duration  cooling_period  cream_fat_content  \\\n",
       "id                                                                         \n",
       "1               54.0             24.0            26.0              100.4   \n",
       "\n",
       "    egg_temperature  egg_yolk_count  final_temperature  lemon_zest_ph  origin  \\\n",
       "id                                                                              \n",
       "1              52.0              11              309.0            3.2  Lisboa   \n",
       "\n",
       "    oven_temperature  preheating_time  salt_ratio  sugar_content  \\\n",
       "id                                                                 \n",
       "1                NaN            207.0       42.74           22.8   \n",
       "\n",
       "    vanilla_extract  quality_class_binary  \n",
       "id                                         \n",
       "1               5.7                     0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_learn['quality_class_binary'] = dataset_learn['quality_class'].replace({'OK': 1, 'KO': 0})\n",
    "dataset_learn = dataset_learn.drop(columns=['quality_class'])\n",
    "dataset_learn.head(1) #just to check if the changes were applied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac50c83",
   "metadata": {},
   "source": [
    "##### **2.5 Export Cleaned Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978f6739",
   "metadata": {},
   "source": [
    "Now we need to export the final dataset for us to be able to work with it on the next notebook(feature engineering).  \n",
    "Export the structurally cleaned data. It still contains NaNs and unscaled numericals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8198562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_learn.to_csv('datasetlearn_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430eaaa6",
   "metadata": {},
   "source": [
    "##### **Conclusion and Strucura Clening Insights**\n",
    "\n",
    "This structural cleaning phase has been successfully completed, resulting in the dataset `datasetlearn_structurally_cleaned.csv`.\n",
    "\n",
    "Insights and Preparation for Modeling\n",
    "\n",
    "- **Focus on Key Variables:** We removed columns with no predictive value (`id`, `notes_baker`) and the uninformative `pastry_type` column, leaving the 14 essential recipe and process characteristics (e.g., `sugar_content`, `oven_temperature`, and `origin`) for modeling.\n",
    "- **Categorical Consistency:** We ensured the `origin` column is standardized to only two consistent, clean values (`Lisboa` and `Porto`) by manually correcting capitalization.\n",
    "- **Binary Target:** The target variable, `quality_class`, was converted into a binary format (`OK`=1, `KO`=0) as required for our classification model. \n",
    "- **Anti-Leakage Confirmed (Crucial Step):** The exported dataset intentionally still contains missing values (`NaNs`) and unscaled numerical features. This is critical: all statistical transformations (Imputation, Scaling, and Encoding) have been **deferred** to **Notebook 3** where the individual Scikit-learn transformers (e.g., `SimpleImputer`, `StandardScaler`, `OneHotEncoder`) will be **manually fitted exclusively on the training data** and then applied to the validation and test sets. This manual process guarantees we completely avoid **data leakage**, fulfilling a core requirement of the project's evaluation criteria.\n",
    "\n",
    "##### **Next Step**\n",
    "\n",
    "The `datasetlearn_structurally_cleaned.csv` is now the clean input for **Notebook 3 (Feature Management)**, where we will perform the necessary data split (Train/Validation/Test) and define the non-leaking preprocessing Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e5bb00",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faad2736",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fc42301",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
