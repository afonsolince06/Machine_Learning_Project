{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cc993f4",
   "metadata": {},
   "source": [
    "# **Modelling and Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85694c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93695220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Ignore ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35a62522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test split data loaded successfully!\n",
      "Full dataset X shape: (5196, 14) | y shape: (5196,)\n",
      "X_train shape: (3117, 14)\n",
      "X_val shape: (1039, 14)\n",
      "X_test shape: (1040, 14)\n",
      "kf splits: 10\n",
      "rkf splits: 14\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load train/val/test split data from notebook3\n",
    "with open(r'Nata_Files\\\\train_test_split.pkl', 'rb') as f:\n",
    "    notebook3_data = pickle.load(f)\n",
    "\n",
    "# Core datasets\n",
    "X = notebook3_data.get('X')\n",
    "y = notebook3_data.get('y')\n",
    "\n",
    "# Splits and processed feature sets\n",
    "X_train = notebook3_data.get('X_train')\n",
    "y_train = notebook3_data.get('y_train')\n",
    "X_val = notebook3_data.get('X_val')\n",
    "y_val = notebook3_data.get('y_val')\n",
    "X_test = notebook3_data.get('X_test')\n",
    "y_test = notebook3_data.get('y_test')\n",
    "X_train_val = notebook3_data.get('X_train_val')\n",
    "y_train_val = notebook3_data.get('y_train_val')\n",
    "\n",
    "numeric_cols = notebook3_data.get('numeric_cols')\n",
    "kf = notebook3_data.get('kf')\n",
    "rkf = notebook3_data.get('rkf')\n",
    "skf = notebook3_data.get('skf')\n",
    "\n",
    "print(\"Train/Val/Test split data loaded successfully!\")\n",
    "if X is not None and y is not None:\n",
    "    print(f\"Full dataset X shape: {X.shape} | y shape: {y.shape}\")\n",
    "if X_train is not None:\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "if X_val is not None:\n",
    "    print(f\"X_val shape: {X_val.shape}\")\n",
    "if X_test is not None:\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "if kf is not None:\n",
    "    try:\n",
    "        print(f\"kf splits: {kf.get_n_splits()}\")\n",
    "    except Exception:\n",
    "        print(\"kf loaded (object), get_n_splits() unavailable for this object\")\n",
    "if rkf is not None:\n",
    "    try:\n",
    "        print(f\"rkf splits: {rkf.get_n_splits()}\")\n",
    "    except Exception:\n",
    "        print(\"rkf loaded (object), get_n_splits() unavailable for this object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ac941e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "794a3abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict_proba(self, X_val):\n",
    "        return self.model.predict_proba(X_val)\n",
    "    \n",
    "    def predict(self, X_val):\n",
    "        return self.model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cab74f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_score_clf(method,X,y,model):\n",
    "    score_train = []\n",
    "    score_val = []\n",
    "    for train_index, val_index in method.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        trained_model = fit_model(model, X_train, y_train)\n",
    "        value_train = eval_clf_model(trained_model, X_train, y_train)\n",
    "        value_val = eval_clf_model(trained_model, X_val, y_val)\n",
    "        score_train.append(value_train)\n",
    "        score_val.append(value_val)\n",
    "\n",
    "    print('Train:', np.mean(score_train))\n",
    "    print('Validation:', np.mean(score_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7d5c788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_score_clf_skf(method, X, y, model):\n",
    "    score_train = []\n",
    "    score_val = []\n",
    "    for train_index, val_index in method.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        trained_model = fit_model(model, X_train, y_train)\n",
    "        value_train = eval_clf_model(trained_model, X_train, y_train)\n",
    "        value_val = eval_clf_model(trained_model, X_val, y_val)\n",
    "        score_train.append(value_train)\n",
    "        score_val.append(value_val)\n",
    "\n",
    "    print('Train:', np.mean(score_train))\n",
    "    print('Validation:', np.mean(score_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac7da53",
   "metadata": {},
   "source": [
    "## **Model Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4271d6a0",
   "metadata": {},
   "source": [
    "Que modelos podemos usar?\n",
    "Isto é um classification problem então podemos descartar logo alguns.\n",
    "Podemos testar :\n",
    "- Logistic Regression\n",
    "- Decision Tree Classifier\n",
    "- Random Forest\n",
    "- K nearest Classifier\n",
    "- stacking /ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d9cd8f",
   "metadata": {},
   "source": [
    "## **Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "848cc021",
   "metadata": {},
   "outputs": [],
   "source": [
    "logr = Predictor(LogisticRegression())\n",
    "logr.fit(X_train, y_train)\n",
    "logr_proba = logr.predict_proba(X_val)[:,1]\n",
    "logr_pred = logr.predict(X_val)\n",
    "\n",
    "\n",
    "dtc = Predictor(DecisionTreeClassifier(max_depth= 5))\n",
    "dtc.fit(X_train, y_train)\n",
    "dtc_proba = dtc.predict_proba(X_val)[:,1]\n",
    "dtc_pred = dtc.predict(X_val)\n",
    "\n",
    "\n",
    "rf = Predictor(RandomForestClassifier())\n",
    "rf.fit(X_train, y_train)\n",
    "rf_proba = rf.predict_proba(X_val)[:,1]\n",
    "rf_pred = rf.predict(X_val)\n",
    "\n",
    "\n",
    "knn_clf = Predictor(KNeighborsClassifier())\n",
    "knn_clf.fit(X_train, y_train)\n",
    "knn_clf_proba = knn_clf.predict_proba(X_val)[:,1]\n",
    "knn_clf_pred = knn_clf.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263bfce2",
   "metadata": {},
   "source": [
    "#### **Logistic Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8221bb4",
   "metadata": {},
   "source": [
    "##### Stratified K-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b01322d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.7400993989296217\n",
      "Validation: 0.7405717355861865\n"
     ]
    }
   ],
   "source": [
    "avg_score_clf_skf(skf, X, y,logr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3390370",
   "metadata": {},
   "source": [
    "#### **Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3721f121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4375    , 0.5625    ],\n",
       "       [0.05050505, 0.94949495],\n",
       "       [0.52272727, 0.47727273],\n",
       "       ...,\n",
       "       [0.30319149, 0.69680851],\n",
       "       [0.80597015, 0.19402985],\n",
       "       [0.79227053, 0.20772947]], shape=(1039, 2))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = Predictor(DecisionTreeClassifier(max_depth= 5))\n",
    "dtc.fit(X_train, y_train)\n",
    "dtc.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437d168e",
   "metadata": {},
   "source": [
    "##### Stratified K-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7e24d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1.0\n",
      "Validation: 0.7036179042537424\n"
     ]
    }
   ],
   "source": [
    "avg_score_clf_skf(skf, X, y, dtc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a1e9d6",
   "metadata": {},
   "source": [
    "#### **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfa36bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "640682c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1.0\n",
      "Validation: 0.7900303838743146\n"
     ]
    }
   ],
   "source": [
    "avg_score_clf_skf(skf, X, y, rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ed67a8",
   "metadata": {},
   "source": [
    "#### **K-Neighbors Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc775ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf19a455",
   "metadata": {},
   "source": [
    "##### Stratified K-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d1a58ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.796510223390843\n",
      "Validation: 0.6968786127167629\n"
     ]
    }
   ],
   "source": [
    "avg_score_clf_skf(skf, X, y, knn_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0e670b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_val, y_proba, y_pred, model):\n",
    "    return {\n",
    "        \"Model\" : model,\n",
    "        \"AUC\": roc_auc_score(y_val, y_proba),\n",
    "        \"Accuracy\": accuracy_score(y_val, y_pred),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "78f5d23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_metrics = []\n",
    "\n",
    "models_metrics.append(get_metrics(y_val, logr_proba, logr_pred, \"Logistic Regression\"))\n",
    "models_metrics.append(get_metrics(y_val, dtc_proba, dtc_pred, \"DTClassifier\"))\n",
    "models_metrics.append(get_metrics(y_val, rf_proba, rf_pred, \"Random Forest\"))\n",
    "models_metrics.append(get_metrics(y_val, knn_clf_proba, knn_clf_pred, \"KNClassifier\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7fb222e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.809067</td>\n",
       "      <td>0.750722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTClassifier</th>\n",
       "      <td>0.768210</td>\n",
       "      <td>0.728585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.833349</td>\n",
       "      <td>0.767084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNClassifier</th>\n",
       "      <td>0.774752</td>\n",
       "      <td>0.726660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          AUC  Accuracy\n",
       "Model                                  \n",
       "Logistic Regression  0.809067  0.750722\n",
       "DTClassifier         0.768210  0.728585\n",
       "Random Forest        0.833349  0.767084\n",
       "KNClassifier         0.774752  0.726660"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models_metrics = pd.DataFrame(models_metrics)\n",
    "df_models_metrics.set_index(\"Model\", inplace=True)\n",
    "\n",
    "df_models_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75b8faf",
   "metadata": {},
   "source": [
    "Fazer ensemble (bagging)?\n",
    "Perguntar ao professor se podemos usar só RF? Vale a pena testar ensemble dps? ir testando\n",
    "A data partitioning aqui está aser hold-out method, gostava de testar Stratified CV da mesma maneira\n",
    "\n",
    "FAZER:\n",
    "- Tune do modelo\n",
    "- Hyperparameters?\n",
    "- Feature selection (if appropriate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0844e8e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
